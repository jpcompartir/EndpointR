<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en-GB"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><title>Process a data frame through OpenAI's Chat Completions API with chunked processing — oai_complete_df • EndpointR</title><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet"><script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/Lato-0.4.10/font.css" rel="stylesheet"><link href="../deps/Fira_Code-0.4.10/font.css" rel="stylesheet"><link href="../deps/Merriweather-0.4.10/font.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet"><link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet"><script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Process a data frame through OpenAI's Chat Completions API with chunked processing — oai_complete_df"><meta name="description" content="This function takes a data frame with text inputs and processes each row through
OpenAI's Chat Completions API using efficient chunked processing. It handles
concurrent requests, automatic retries, and structured output validation while
writing results progressively to disk."><meta property="og:description" content="This function takes a data frame with text inputs and processes each row through
OpenAI's Chat Completions API using efficient chunked processing. It handles
concurrent requests, automatic retries, and structured output validation while
writing results progressively to disk."></head><body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-dark" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">EndpointR</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">0.2</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto"><li class="nav-item"><a class="nav-link" href="../articles/api_keys.html">Get Started</a></li>
<li class="active nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles"><li><h6 class="dropdown-header" data-toc-skip>Getting Started</h6></li>
    <li><a class="dropdown-item" href="../articles/api_keys.html">API Key Management</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>Hugging Face</h6></li>
    <li><a class="dropdown-item" href="../articles/hugging_face_inference.html">Hugging Face Inference Endpoints</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>LLM Providers (OpenAI, Anthropic)</h6></li>
    <li><a class="dropdown-item" href="../articles/llm_providers.html">Working with Major LLM Providers</a></li>
    <li><a class="dropdown-item" href="../articles/structured_outputs_json_schema.html">Structured Outputs with JSON Schema</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>Embeddings</h6></li>
    <li><a class="dropdown-item" href="../articles/embeddings_providers.html">Embeddings Providers</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>Advanced Topics</h6></li>
    <li><a class="dropdown-item" href="../articles/improving_performance.html">Improving Performance</a></li>
  </ul></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul><ul class="navbar-nav"><li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json"></form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/jpcompartir/EndpointR" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul></div>


  </div>
</nav><div class="container template-reference-topic">
<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Process a data frame through OpenAI's Chat Completions API with chunked processing</h1>
      <small class="dont-index">Source: <a href="https://github.com/jpcompartir/EndpointR/tree/main/R/openai_completions.R" class="external-link"><code>R/openai_completions.R</code></a></small>
      <div class="d-none name"><code>oai_complete_df.Rd</code></div>
    </div>

    <div class="ref-description section level2">
    <p>This function takes a data frame with text inputs and processes each row through
OpenAI's Chat Completions API using efficient chunked processing. It handles
concurrent requests, automatic retries, and structured output validation while
writing results progressively to disk.</p>
    </div>

    <div class="section level2">
    <h2 id="ref-usage">Usage<a class="anchor" aria-label="anchor" href="#ref-usage"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">oai_complete_df</span><span class="op">(</span></span>
<span>  <span class="va">df</span>,</span>
<span>  <span class="va">text_var</span>,</span>
<span>  <span class="va">id_var</span>,</span>
<span>  model <span class="op">=</span> <span class="st">"gpt-4.1-nano"</span>,</span>
<span>  output_dir <span class="op">=</span> <span class="st">"auto"</span>,</span>
<span>  system_prompt <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  schema <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  chunk_size <span class="op">=</span> <span class="fl">1000</span>,</span>
<span>  concurrent_requests <span class="op">=</span> <span class="fl">1L</span>,</span>
<span>  max_retries <span class="op">=</span> <span class="fl">5L</span>,</span>
<span>  timeout <span class="op">=</span> <span class="fl">30</span>,</span>
<span>  temperature <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  max_tokens <span class="op">=</span> <span class="fl">500L</span>,</span>
<span>  key_name <span class="op">=</span> <span class="st">"OPENAI_API_KEY"</span>,</span>
<span>  endpoint_url <span class="op">=</span> <span class="st">"https://api.openai.com/v1/chat/completions"</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div class="section level2">
    <h2 id="arguments">Arguments<a class="anchor" aria-label="anchor" href="#arguments"></a></h2>


<dl><dt id="arg-df">df<a class="anchor" aria-label="anchor" href="#arg-df"></a></dt>
<dd><p>Data frame containing text to process</p></dd>


<dt id="arg-text-var">text_var<a class="anchor" aria-label="anchor" href="#arg-text-var"></a></dt>
<dd><p>Column name (unquoted) containing text inputs</p></dd>


<dt id="arg-id-var">id_var<a class="anchor" aria-label="anchor" href="#arg-id-var"></a></dt>
<dd><p>Column name (unquoted) for unique row identifiers</p></dd>


<dt id="arg-model">model<a class="anchor" aria-label="anchor" href="#arg-model"></a></dt>
<dd><p>OpenAI model to use (default: "gpt-4.1-nano")</p></dd>


<dt id="arg-output-dir">output_dir<a class="anchor" aria-label="anchor" href="#arg-output-dir"></a></dt>
<dd><p>Path to directory for the .parquet chunks. "auto" generates a timestamped directory name. If NULL, uses a temporary directory.</p></dd>


<dt id="arg-system-prompt">system_prompt<a class="anchor" aria-label="anchor" href="#arg-system-prompt"></a></dt>
<dd><p>Optional system prompt applied to all requests</p></dd>


<dt id="arg-schema">schema<a class="anchor" aria-label="anchor" href="#arg-schema"></a></dt>
<dd><p>Optional JSON schema for structured output (json_schema object or list)</p></dd>


<dt id="arg-chunk-size">chunk_size<a class="anchor" aria-label="anchor" href="#arg-chunk-size"></a></dt>
<dd><p>Number of texts to process in each batch (default: 5000)</p></dd>


<dt id="arg-concurrent-requests">concurrent_requests<a class="anchor" aria-label="anchor" href="#arg-concurrent-requests"></a></dt>
<dd><p>Integer; number of concurrent requests (default: 5)</p></dd>


<dt id="arg-max-retries">max_retries<a class="anchor" aria-label="anchor" href="#arg-max-retries"></a></dt>
<dd><p>Maximum retry attempts per failed request (default: 5)</p></dd>


<dt id="arg-timeout">timeout<a class="anchor" aria-label="anchor" href="#arg-timeout"></a></dt>
<dd><p>Request timeout in seconds (default: 30)</p></dd>


<dt id="arg-temperature">temperature<a class="anchor" aria-label="anchor" href="#arg-temperature"></a></dt>
<dd><p>Sampling temperature (0-2), lower = more deterministic (default: 0)</p></dd>


<dt id="arg-max-tokens">max_tokens<a class="anchor" aria-label="anchor" href="#arg-max-tokens"></a></dt>
<dd><p>Maximum tokens per response (default: 500)</p></dd>


<dt id="arg-key-name">key_name<a class="anchor" aria-label="anchor" href="#arg-key-name"></a></dt>
<dd><p>Name of environment variable containing the API key (default: OPENAI_API_KEY)</p></dd>


<dt id="arg-endpoint-url">endpoint_url<a class="anchor" aria-label="anchor" href="#arg-endpoint-url"></a></dt>
<dd><p>OpenAI API endpoint URL</p></dd>

</dl></div>
    <div class="section level2">
    <h2 id="value">Value<a class="anchor" aria-label="anchor" href="#value"></a></h2>
    <p>A tibble with the original id column and additional columns:</p><ul><li><p><code>content</code>: API response content (text or JSON string if schema used)</p></li>
<li><p><code>.error</code>: Logical indicating if request failed</p></li>
<li><p><code>.error_msg</code>: Error message if failed, NA otherwise</p></li>
<li><p><code>.chunk</code>: Chunk number for tracking</p></li>
</ul></div>
    <div class="section level2">
    <h2 id="details">Details<a class="anchor" aria-label="anchor" href="#details"></a></h2>
    <p>This function provides a data frame interface to the chunked processing
capabilities of <code><a href="oai_complete_chunks.html">oai_complete_chunks()</a></code>. It extracts the specified text column,
processes texts in configurable chunks with concurrent API requests, and returns
results matched to the original data through the <code>id_var</code> parameter.</p>
<p>The chunking approach enables processing of large data frames without memory
constraints. Results are written progressively as parquet files (either to a specified
directory or auto-generated) and then read back as the return value.</p>
<p>When using structured outputs with a <code>schema</code>, responses are validated against
the JSON schema and stored as JSON strings. Post-processing may be needed to
unnest these into separate columns.</p>
<p>Failed requests are marked with <code>.error = TRUE</code> and include error messages,
allowing for easy filtering and retry logic on failures.</p>
<p>Avoid risk of data loss by setting a low-ish chunk_size (e.g. 5,000, 10,000). Each chunk is written to a <code>.parquet</code> file in the <code>output_dir=</code> directory, which also contains a <code>metadata.json</code> file. Be sure to add output directories to .gitignore!</p>
    </div>

    <div class="section level2">
    <h2 id="ref-examples">Examples<a class="anchor" aria-label="anchor" href="#ref-examples"></a></h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="cn">FALSE</span><span class="op">)</span> <span class="op">{</span> <span class="co"># \dontrun{</span></span></span>
<span class="r-in"><span><span class="co"># Basic usage with a data frame</span></span></span>
<span class="r-in"><span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu">tibble</span><span class="fu">::</span><span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>  doc_id <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">3</span>,</span></span>
<span class="r-in"><span>  text <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>    <span class="st">"I absolutely loved this product!"</span>,</span></span>
<span class="r-in"><span>    <span class="st">"Terrible experience, would not recommend."</span>,</span></span>
<span class="r-in"><span>    <span class="st">"It was okay, nothing special."</span></span></span>
<span class="r-in"><span>  <span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="va">results</span> <span class="op">&lt;-</span> <span class="fu">oai_complete_df</span><span class="op">(</span></span></span>
<span class="r-in"><span>  df <span class="op">=</span> <span class="va">df</span>,</span></span>
<span class="r-in"><span>  text_var <span class="op">=</span> <span class="va">text</span>,</span></span>
<span class="r-in"><span>  id_var <span class="op">=</span> <span class="va">doc_id</span>,</span></span>
<span class="r-in"><span>  system_prompt <span class="op">=</span> <span class="st">"Summarise the sentiment in one word."</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Structured extraction with schema</span></span></span>
<span class="r-in"><span><span class="va">sentiment_schema</span> <span class="op">&lt;-</span> <span class="fu"><a href="create_json_schema.html">create_json_schema</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>  name <span class="op">=</span> <span class="st">"sentiment_analysis"</span>,</span></span>
<span class="r-in"><span>  schema <span class="op">=</span> <span class="fu"><a href="schema_object.html">schema_object</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>    sentiment <span class="op">=</span> <span class="fu"><a href="schema_string.html">schema_string</a></span><span class="op">(</span><span class="st">"positive, negative, or neutral"</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>    confidence <span class="op">=</span> <span class="fu"><a href="schema_number.html">schema_number</a></span><span class="op">(</span><span class="st">"confidence score between 0 and 1"</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>    required <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="st">"sentiment"</span>, <span class="st">"confidence"</span><span class="op">)</span></span></span>
<span class="r-in"><span>  <span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="va">results</span> <span class="op">&lt;-</span> <span class="fu">oai_complete_df</span><span class="op">(</span></span></span>
<span class="r-in"><span>  df <span class="op">=</span> <span class="va">df</span>,</span></span>
<span class="r-in"><span>  text_var <span class="op">=</span> <span class="va">text</span>,</span></span>
<span class="r-in"><span>  id_var <span class="op">=</span> <span class="va">doc_id</span>,</span></span>
<span class="r-in"><span>  schema <span class="op">=</span> <span class="va">sentiment_schema</span>,</span></span>
<span class="r-in"><span>  temperature <span class="op">=</span> <span class="fl">0</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Post-process structured results</span></span></span>
<span class="r-in"><span><span class="va">results</span> <span class="op">|&gt;</span></span></span>
<span class="r-in"><span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html" class="external-link">filter</a></span><span class="op">(</span><span class="op">!</span><span class="va">.error</span><span class="op">)</span> <span class="op">|&gt;</span></span></span>
<span class="r-in"><span>  <span class="fu">dplyr</span><span class="fu">::</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>parsed <span class="op">=</span> <span class="fu">purrr</span><span class="fu">::</span><span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html" class="external-link">map</a></span><span class="op">(</span><span class="va">content</span>, <span class="va">safely_from_json</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span></span>
<span class="r-in"><span>  <span class="fu">tidyr</span><span class="fu">::</span><span class="fu"><a href="https://tidyr.tidyverse.org/reference/unnest_wider.html" class="external-link">unnest_wider</a></span><span class="op">(</span><span class="va">parsed</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span> <span class="co"># }</span></span></span>
</code></pre></div>
    </div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside></div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://github.com/jpcompartir" class="external-link">Jack Penzer</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer></div>





  </body></html>

