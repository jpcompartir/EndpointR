% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hf_embed.R
\name{hf_embed_df}
\alias{hf_embed_df}
\title{Generate embeddings for texts in a data frame}
\usage{
hf_embed_df(
  df,
  text_var,
  endpoint_url,
  key_name,
  id_var,
  batch_size = NULL,
  concurrent_requests = 1,
  max_retries = 3,
  timeout = 10,
  progress = TRUE,
  validate = FALSE,
  include_errors = TRUE
)
}
\arguments{
\item{df}{A data frame containing texts to embed}

\item{text_var}{Name of the column containing text to embed}

\item{endpoint_url}{The URL of the Hugging Face Inference API endpoint}

\item{key_name}{Name of the environment variable containing the API key}

\item{id_var}{Name of the column to use as ID}

\item{batch_size}{Number of texts to process in one batch (NULL for no batching)}

\item{concurrent_requests}{Number of requests to send at once. Some APIs do not allow for multiple requests.}

\item{max_retries}{Maximum number of retry attempts for failed requests.}

\item{timeout}{Request timeout in seconds}

\item{progress}{Whether to display a progress bar}

\item{validate}{Whether to validate the endpoint before creating requests}

\item{include_errors}{Whether to include rows with errors in the result}
}
\value{
A data frame with the original data plus embedding columns
}
\description{
High-level function to generate embeddings for texts in a data frame.
This function handles the entire process from request creation to
response processing, with options for batching & parallel execution.
Setting the number of retries,
}
\examples{
\dontrun{
  # Generate embeddings for a data frame
  df <- data.frame(
    id = 1:3,
    text = c("First example", "Second example", "Third example")
  )

  # Use parallel processing without batching
  embeddings_df <- hf_embed_df(
    df = df,
    text_var = text,
    endpoint_url = "https://my-endpoint.huggingface.cloud",
    id_var = id,
    parallel = TRUE,
    batch_size = NULL
  )

  # Use batching without parallel processing
  embeddings_df <- hf_embed_df(
    df = df,
    text_var = text,
    endpoint_url = "https://my-endpoint.huggingface.cloud",
    id_var = id,
    parallel = FALSE,
    batch_size = 10
  )

  # Use both batching and parallel processing
  embeddings_df <- hf_embed_df(
    df = df,
    text_var = text,
    endpoint_url = "https://my-endpoint.huggingface.cloud",
    id_var = id,
    parallel = TRUE,
    batch_size = 10
  )
}
}
