% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hf_embed.R
\name{hf_embed_batch}
\alias{hf_embed_batch}
\title{Generate batches of embeddings for a list of texts}
\usage{
hf_embed_batch(
  texts,
  endpoint_url,
  key_name,
  ...,
  batch_size = 8,
  include_texts = TRUE,
  concurrent_requests = 1,
  max_retries = 5,
  timeout = 10,
  validate = FALSE,
  relocate_col = 2
)
}
\arguments{
\item{texts}{Vector or list of character strings to get embeddings for}

\item{endpoint_url}{The URL of the Hugging Face Inference API endpoint}

\item{key_name}{Name of the environment variable containing the API key}

\item{...}{ellipsis sent to \code{hf_perform_request} TODO (reserved ATM)}

\item{batch_size}{Number of texts to process in one batch}

\item{include_texts}{Whether to return the original texts in the return tibble}

\item{concurrent_requests}{Number of requests to send simultaneously}

\item{max_retries}{Maximum number of retry attempts for failed requests}

\item{timeout}{Request timeout in seconds}

\item{validate}{Whether to validate the endpoint before creating the request}
}
\value{
A tibble containing the embedding vectors
}
\description{
High-level function to generate embeddings for multiple text strings.
This function handles batching and parallel processing of embedding requests, and attempts to handle errors gracefully.
}
\examples{
\dontrun{
  # Generate embeddings for multiple texts using default batch size
  embeddings <- hf_embed_batch(
    texts = c("First example", "Second example", "Third example"),
    endpoint_url = "https://my-endpoint.huggingface.cloud"
  )

  # With custom batch size and concurrent requests
  embeddings <- hf_embed_batch(
    texts = c("First example", "Second example", "Third example"),
    endpoint_url = "https://my-endpoint.huggingface.cloud",
    batch_size = 10,
    concurrent_requests = 2
  )
}
}
