% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hf_classify.R
\name{hf_classify_chunks}
\alias{hf_classify_chunks}
\title{Title}
\usage{
hf_classify_chunks(
  texts,
  ids,
  endpoint_url,
  ...,
  tidy_func = tidy_classification_response,
  output_dir = "auto",
  chunk_size = 5000L,
  concurrent_requests = 5L,
  max_retries = 5L,
  timeout = 30L,
  key_name = "HF_API_KEY"
)
}
\arguments{
\item{texts}{Character vector of texts to classify}

\item{ids}{Vector of unique identifiers corresponding to each text (same length as texts)}

\item{endpoint_url}{Hugging Face Embedding Endpoint}

\item{tidy_func}{Function to process API responses, defaults to
\code{tidy_classification_response}}

\item{output_dir}{Path to directory for the .parquet chunks}

\item{chunk_size}{Number of texts to process in each chunk before writing to disk (default: 5000)}

\item{concurrent_requests}{Integer; number of concurrent requests (default: 5)}

\item{max_retries}{Integer; maximum retry attempts (default: 5)}

\item{timeout}{Numeric; request timeout in seconds (default: 20)}

\item{key_name}{Name of environment variable containing the API key}
}
\description{
Title
}
