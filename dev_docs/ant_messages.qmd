---
title: "ant_messages"
format: html
---

```{r}
library(httr2)
library(purrr)
library(jsonlite)
library(tidyr)
library(dplyr)
```

# Structured Outputs

HTTP 400 errors (discovery: due to structured outputs not being supported in certain models and I switched to default to Haiku for testing/\$\$\$)

```{r}
req <- ant_build_messages_request(input = "This is terrible, fin.")

resp <- req_perform(req, verbosity = 1)
resp |>  resp_body_string() |>  prettify()


schema <- create_json_schema(
  name = "capital_response",
  schema = schema_object(
    country = schema_string(),
    capital = schema_string(),
    required = c("country", "capital")
  )
)

structured_req <- ant_build_messages_request(input = "Well I would walk five hundred miles, to visit the noble city of Prague.", schema = schema, model = "claude-sonnet-4-5")

structured_req |>  req_dry_run() |>  toJSON() |>  jsonlite::flatten()

structured_resp <- req_perform(structured_req)

ant_schema <- .ant_format_schema(schema)
ant_structured_req <- ant_build_messages_request(input = "Well I would walk five hundred miles, to visit the noble city of Prague.", schema = ant_schema)

setdiff(ant_structured_req |>  req_dry_run(), structured_req |>  req_dry_run())

ant_structured_resp <- req_perform(ant_structured_req)

struc_dry <- req_dry_run(structured_req)
ant_dry <- req_dry_run(ant_structured_req)

setdiff(struc_dry, ant_dry)
identical(struc_dry, ant_dry)

```

```         
"output_format": {
  "type": "json_schema",
  "schema": {
    "type": "object",
    "properties": {
      "name": {"type": "string"},
      "email": {"type": "string"},
      "plan_interest": {"type": "string"},
      "demo_requested": {"type": "boolean"}
    },
    "required": ["name", "email", "plan_interest", "demo_requested"],
    "additionalProperties": false
  }
}
```

```{r}
list_schema <- list(
    type = "json_schema",
    schema = list(
      type = "object",
      properties = list(
        country = list(type = "string"),
        capital = list(type = "string")
      ),
      required = c("country", "capital"),
      additionalProperties = FALSE
    )
)

```

```{r}
list_schema_req <- ant_build_messages_request("Prague is my favourite city, I went there when I visited The Czech Republic", schema = list_schema, model = "claude-sonnet-4-5")
list_schema_req |>  req_dry_run()
list_schema_resp <- req_perform(list_schema_req, verbosity = 1)
```

If we want to surface the actual errors we'll need to re-write a bunch of the package. Thought about this earlier but wasn't sure. The structured outputs error with Haiku makes me think it's probs worth.

```{r}
req_schema_haiku <- ant_build_messages_request("Prague is my favourite city, I went there when I visited The Czech Republic", schema = list_schema)

req_schema_haiku <- req_schema_haiku |> 
  req_error(is_error = ~FALSE)

resp <- req_schema_haiku |> 
  req_perform(verbosity = 1) 

resp_body_json(resp)[["error"]][["message"]]
resp |>  resp_status()
```

## Nested Schemas

```{r}
absa_entities_schema <- create_json_schema(
  name = "entities",
  strict = TRUE,
  description = "List of entity-sentiment",
  schema = schema_object(
    entities = schema_array(
      schema_object(
        entity = schema_string(
          description = "Name of the named entity"),
        sentiment = schema_string(
          enum = c("positive", "negative", "neutral"),
          "sentiment associated with the entity")
      )
    )
  )
)

req <- ant_build_messages_request(
  "Apple have been wonderful, Microsoft... not so much. And by not so much I mean pathetic.",
  schema = absa_entities_schema,
  model = "claude-sonnet-4-5"
)

resp <- httr2::req_perform(req)

resp |>  resp_body_json() |> 
  purrr::pluck("content", 1, "text") |> 
  fromJSON() |>  
  pluck('entities')
```

```         
     entity sentiment
1     Apple  positive
2 Microsoft  negative
```

Now we run it again and expect an error, and that the error message will actually be viewable rather than a generic error message with the status code:

```{r}
error_400 <- req <- ant_build_messages_request(
  "Apple have been wonderful, Microsoft... not so much. And by not so much I mean pathetic.",
  schema = absa_entities_schema
)
resp_400 <- req_perform(error_400)
.extract_api_error(resp_400)
resp_400 |>  resp_body_json()
```

# text - ant_complete_text

```{r}
ant_complete_text("What's going on dawg?")

absa_test <- ant_complete_text("Apple have been wonderful, Microsoft... not so much. And by not so much I mean pathetic.",
                  model = "claude-sonnet-4-5",
                  system_prompt = "Follow the schema and help the user.",
                  schema = absa_entities_schema)

absa_test$entities |>  
  bind_rows()
```

# chunks - ant_complete_chunks

```{r, chunk_df_test_texts_ids}
ids <- c(paste0("id_", 1:10))
texts <- c(
  "The kettle whistled at 6 AM.",
  "Machine learning models require substantial computational resources and careful hyperparameter tuning to achieve optimal performance on complex datasets with high dimensionality and temporal dependencies.",
  "She bought milk.",
  "Quantum entanglement remains one of the most counterintuitive phenomena in physics, suggesting that particles can influence each other instantaneously across arbitrary distances, challenging classical notions of locality and causality that governed physics for centuries.",
  "It rained yesterday.",
  "The algorithm iterated through 47 million records in under three minutes, filtering by date and category before aggregating results into hierarchical structures.",
  "Dogs bark.",
  "Brexit negotiations involved trade agreements, fisheries disputes, regulatory alignment across financial services, customs procedures, and residency rights for citizens living abroad, spanning four years of complex bilateral discussions.",
  "Coffee is hot.",
  "The startup pivoted twice before finding product-market fit in the enterprise SaaS space, eventually acquiring three smaller competitors and expanding to eighteen countries across three continents."
)

word_summary_schema <- create_json_schema(
  name = "summary",
  schema = schema_object(
    summary = schema_string(),
    required = list("summary")
 
     )
)
```

```{r, ant_complete_chunks}
chunks_test <- ant_complete_chunks(
  texts = texts,
  ids = ids,
  id_col_name = "id_column",
  output_dir = "test_dir/anthropic/chunks/no_schema",
  model = "claude-haiku-4-5",
  concurrent_requests = 10,
  chunk_size = 10,
  system_prompt = "Write a one-word summary of the input text",
  key_name = "ANTHROPIC_API_KEY"
)
```

```{r}
chunks_text_w_schema <- ant_complete_chunks(
  texts = texts,
  ids = ids,
  id_col_name = "id_column",
  output_dir = "test_dir/anthropic/chunks/schema",
  model = "claude-haiku-4-5",
  concurrent_requests = 10,
  chunk_size = 10,
  system_prompt = "Write a one-word summary of the input text",
  schema = word_summary_schema,
  key_name = "ANTHROPIC_API_KEY"
)

chunks_text_w_schema |> 
  mutate(content = purrr::map(content, \(x) safely_from_json(x))) |> 
  unnest_wider(content)
```

# df - ant_complete_df

```{r, ant_complete_df}
df <- tibble(
  ids = ids,
  text = texts
)

df_test <- df |> ant_complete_df(
  text_var = text,
  id_var = ids,
  output_dir = "test_dir/anthropic/df/no_schema",
  chunk_size = 10,
  concurrent_requests = 10,
  model = "claude-haiku-4-5",
  system_prompt = "Write 1 word to describe the text",
)

df_test
```

```{r}
df_w_schema <-df |> ant_complete_df(
  text_var = text,
  id_var = ids,
  output_dir = "test_dir/anthropic/df/schema",
  chunk_size = 10,
  concurrent_requests = 10,
  model = "claude-haiku-4-5",
  system_prompt = "Write 1 word to describe the text",
  schema = word_summary_schema
)

df_w_schema |> 
  mutate(content = map(content, \(x) fromJSON(x))) |> 
  unnest_wider(content)
```

```{r}
df_no_system_prompt <- df |>
  ant_complete_df(
  text_var = text,
  id_var = ids,
  output_dir = "test_dir/anthropic/df/no_system_prompt",
  chunk_size = 10,
  concurrent_requests = 10,
  model = "claude-haiku-4-5",
  system_prompt = NULL,
  max_tokens = 2,
  schema = word_summary_schema
)

df_no_system_prompt
```
