---
title: "integrations"
format: html
---

```{r, setup}
library(tidyverse)
library(httr2)
library(EndpointR)
library(jsonlite)

n_tests <- 5
test_df <- tibble(
    id = 1:n_tests,
    text = paste("This is test sentence number", 1:n_tests)
  )
```

Space for integration tests (useful for not relying on unit tests when interacting with real APIs)

# OpenAI

## oai embed

```{r, invalid_model_oai_embed}
oai_embed_invalid_model <- oai_embed_df(
    test_df,
    text_var = "text",
    id_var = "id",
    model = "text-embedding-FAKE-model",
    output_dir = NULL,
    concurrent_requests = n_tests
  )

oai_embed_invalid_model |> dplyr::select(id, .error, .error_msg, .status)
# expect: .error = TRUE, .status = 404, .error_msg contains model info
```

invalid API key returns 401 authentication error

```{r, oai_embed_401_auth}
oai_embed_bad_auth <- oai_embed_df(
  test_df,
  text_var = "text",
  id_var = "id",
  model = "text-embedding-3-small",
  key_name = "FAKE_API_KEY",
  output_dir = NULL,
  concurrent_requests = n_tests
)

oai_embed_bad_auth |> dplyr::select(id, .error, .error_msg, .status)
# expect: .error = TRUE, .status = 401, .error_msg mentions authentication
```

now succeed:

```{r oai_embed_success}
oai_embed_success <- oai_embed_df(
  test_df, 
  text_var = text, 
  id_var = id, 
  model = "text-embedding-3-small",
  output_dir = NULL,
  concurrent_requests = n_tests)

oai_embed_success
```

## oai completions

invalid API key for completions

```{r}
oai_complete_bad_auth <- oai_complete_df(
  test_df,
  text_var = "text",
  id_var = "id",
  model = "gpt-4o-mini",
  system_prompt = "Summarize in one word.",
  key_name = "FAKE_API_KEY",
  output_dir = NULL,
  concurrent_requests = n_tests
)

oai_complete_bad_auth |> dplyr::select(id, .error, .error_msg, .status)

# expect: .error = TRUE, .status = 401
```

```{r}
oai_complete_good_auth <- oai_complete_df(
  test_df,
  text_var = "text",
  id_var = "id",
  model = "gpt-4o-mini",
  system_prompt = "Summarize in one word.",
  key_name = "OPENAI_API_KEY",
  output_dir = NULL,
  concurrent_requests = n_tests
)

oai_complete_good_auth
```

# Hugging Face

## hf embed

non-existent HuggingFace model

```{r}
 hf_embed_invalid_model <- hf_embed_df(
   test_df,
   text_var = "text",
   id_var = "id",
   endpoint_url = "https://api-inference.huggingface.co/pipeline/feature-extraction/FAKE-model-404",
   key_name = "HF_TEST_API_KEY",
   output_dir = NULL,
   concurrent_requests = n_tests
  )

hf_embed_invalid_model |> dplyr::select(id, .error, .error_msg, .status)

# expect: .error = TRUE, .status = 410, .error_msg mentions mhttps://api-inference.huggingface.co is no longer...
```

invalid HuggingFace token

```{r, invalid_key_hf_embed}
hf_embed_bad_auth <- hf_embed_df(
  test_df, 
  text_var = "text",
  id_var = "id", 
  endpoint_url = "https://router.huggingface.co/hf-inference/models/sentence-transformers/all-MiniLM-L6-v2/pipeline/sentence-similarity", 
  key_name = "FAKE_API_KEY",
  output_dir = NULL,
  concurrent_requests = n_tests)

hf_embed_bad_auth |> dplyr::select(id, .error, .error_msg, .status) 

# expect: .error = TRUE, .status = 401
```

Non-existent classification model

```{r, invalid_model_hf_classify}
hf_classify_invalid_model <- hf_classify_df(
  test_df, 
  text_var = "text", 
  id_var = "id", 
  endpoint_url = "https://api-inference.huggingface.co/pipeline/feature-extraction/FAKE-model-404",
  output_dir = NULL,
  key_name = "HF_TEST_API_KEY",
  concurrent_requests = n_tests
  )

hf_classify_invalid_model |> dplyr::select(id, .error, .error_msg, .status) 
# expect: .error = TRUE, .status = 410
```

Using an embedding model for classification (wrong task type)

```{r, bad_task_hf_classify}
hf_classify_wrong_task <- hf_classify_df(
  test_df, 
  text_var = text, 
  id_var = id, 
  endpoint_url = "https://router.huggingface.co/hf-inference/models/sentence-transformers/all-MiniLM-L6-v2/pipeline/sentence-similarity",
  key_name = "HF_TEST_API_KEY",
  output_dir = NULL,
  concurrent_requests = n_tests)

hf_classify_wrong_task |> dplyr::select(id, .error, .error_msg, .status) 

# expect: .error = TRUE, error message should indicate task mismatch, .status = 400
```

# Anthroic

```{r, chunk_df_test_texts_ids}
ids <- c(paste0("id_", 1:10))
texts <- c(
  "The kettle whistled at 6 AM.",
  "Machine learning models require substantial computational resources and careful hyperparameter tuning to achieve optimal performance on complex datasets with high dimensionality and temporal dependencies.",
  "She bought milk.",
  "Quantum entanglement remains one of the most counterintuitive phenomena in physics, suggesting that particles can influence each other instantaneously across arbitrary distances, challenging classical notions of locality and causality that governed physics for centuries.",
  "It rained yesterday.",
  "The algorithm iterated through 47 million records in under three minutes, filtering by date and category before aggregating results into hierarchical structures.",
  "Dogs bark.",
  "Brexit negotiations involved trade agreements, fisheries disputes, regulatory alignment across financial services, customs procedures, and residency rights for citizens living abroad, spanning four years of complex bilateral discussions.",
  "Coffee is hot.",
  "The startup pivoted twice before finding product-market fit in the enterprise SaaS space, eventually acquiring three smaller competitors and expanding to eighteen countries across three continents."
)

word_summary_schema <- create_json_schema(
  name = "summary",
  schema = schema_object(
    summary = schema_string(),
    required = list("summary")
 
     )
)
```

## chunks - ant_complete_chunks

```{r, ant_complete_chunks}
chunks_test <- ant_complete_chunks(
  texts = texts,
  ids = ids,
  id_col_name = "id_column",
  output_dir = "test_dir/anthropic/chunks/no_schema",
  model = "claude-haiku-4-5",
  concurrent_requests = 10,
  chunk_size = 10,
  system_prompt = "Write a one-word summary of the input text",
  key_name = "ANTHROPIC_API_KEY"
)
```

```{r}
chunks_text_w_schema <- ant_complete_chunks(
  texts = texts,
  ids = ids,
  id_col_name = "id_column",
  output_dir = "test_dir/anthropic/chunks/schema",
  model = "claude-haiku-4-5",
  concurrent_requests = 10,
  chunk_size = 10,
  system_prompt = "Write a one-word summary of the input text",
  schema = word_summary_schema,
  key_name = "ANTHROPIC_API_KEY"
)

chunks_text_w_schema |> 
  mutate(content = purrr::map(content, \(x) safely_from_json(x))) |> 
  unnest_wider(content)
```

## df - ant_complete_df

```{r, ant_complete_df}
df <- tibble(
  ids = ids,
  text = texts
)

df_test <- df |> ant_complete_df(
  text_var = text,
  id_var = ids,
  output_dir = "test_dir/anthropic/df/no_schema",
  chunk_size = 10,
  concurrent_requests = 10,
  model = "claude-haiku-4-5",
  system_prompt = "Write 1 word to describe the text",
)

df_test
```

```{r}
df_w_schema <-df |> ant_complete_df(
  text_var = text,
  id_var = ids,
  output_dir = "test_dir/anthropic/df/schema",
  chunk_size = 10,
  concurrent_requests = 10,
  model = "claude-haiku-4-5",
  system_prompt = "Write 1 word to describe the text",
  schema = word_summary_schema
)

df_w_schema |> 
  mutate(content = map(content, \(x) fromJSON(x))) |> 
  unnest_wider(content)
```

```{r}
df_no_system_prompt <- df |>
  ant_complete_df(
  text_var = text,
  id_var = ids,
  output_dir = "test_dir/anthropic/df/no_system_prompt",
  chunk_size = 10,
  concurrent_requests = 10,
  model = "claude-haiku-4-5",
  system_prompt = NULL,
  max_tokens = 2,
  schema = word_summary_schema
)

df_no_system_prompt
```
