<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Improving Performance • EndpointR</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Improving Performance">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">EndpointR</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="Released version">0.2</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><h6 class="dropdown-header" data-toc-skip>Getting Started</h6></li>
    <li><a class="dropdown-item" href="../articles/api_keys.html">API Key Management</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>Hugging Face</h6></li>
    <li><a class="dropdown-item" href="../articles/hugging_face_inference.html">Hugging Face Inference Endpoints</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>LLM Providers (OpenAI, Anthropic)</h6></li>
    <li><a class="dropdown-item" href="../articles/llm_providers.html">Working with Major LLM Providers</a></li>
    <li><a class="dropdown-item" href="../articles/structured_outputs_json_schema.html">Structured Outputs with JSON Schema</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>Embeddings</h6></li>
    <li><a class="dropdown-item" href="../articles/embeddings_providers.html">Embeddings Providers</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><h6 class="dropdown-header" data-toc-skip>Advanced Topics</h6></li>
    <li><a class="dropdown-item" href="../articles/improving_performance.html">Improving Performance</a></li>
  </ul>
</li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-news" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">News</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-news">
<li><h6 class="dropdown-header" data-toc-skip>Releases</h6></li>
    <li><a class="dropdown-item" href="../news/index.html#endpointr-012">Version 0.1.2</a></li>
    <li><a class="dropdown-item" href="../news/index.html#endpointr-011">Version 0.1.1</a></li>
    <li><a class="dropdown-item" href="../news/index.html#endpointr-010">Version 0.1.0</a></li>
    <li><hr class="dropdown-divider"></li>
    <li><a class="dropdown-item" href="../news/index.html">Changelog</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/jpcompartir/EndpointR" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Improving Performance</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/jpcompartir/EndpointR/tree/main/vignettes/improving_performance.Rmd" class="external-link"><code>vignettes/improving_performance.Rmd</code></a></small>
      <div class="d-none name"><code>improving_performance.Rmd</code></div>
    </div>

    
    
<p>In this vignette we’ll look at strategies for improving the
throughput and performance of EndpointR’s functions. Our goal will be to
move from sending single requests to sending multiple batches
simultaneously.</p>
<p>Before we get into how, let’s go a bit further into why.</p>
<div class="section level2">
<h2 id="understanding-the-time-problem">Understanding the Time Problem<a class="anchor" aria-label="anchor" href="#understanding-the-time-problem"></a>
</h2>
<p>For each row of our data frame, we need to create a request which we
will then perform. We perform the request by sending our information
over the internet to the endpoint. The endpoint accepts our request,
performs any computation, and sends a successful response or an error.
Each step has an associated cost in time, and the cost for each step is
not equal - some steps are more costly than others.</p>
<p>Creating each request is almost instant, but if we have a larger data
frame - e.g. with 100,000 rows: creating 100,000 requests simultaneously
will take
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mo>≈</mo><annotation encoding="application/x-tex">\approx</annotation></semantics></math>
30s-90s. If we create them all at once, we’ll have to wait the full
amount of time before we begin sending requests. Clearly this is
wasteful - if we had created the first request and sent it, we would
save at least 90 seconds.</p>
<p>Sending each request to the endpoint and waiting for it to process
will usually take a lot longer than preparing the request. Therefore, if
we can find ways to reduce the time we spend waiting here, we should be
able to reduce the overall time it takes to prepare and send our
requests significantly.</p>
<blockquote>
<p>This vignette will focus mainly on the <code><a href="../reference/hf_embed_df.html">hf_embed_df()</a></code>
function and the options we have for improving throughput of requests.
The same ideas apply to the <code><a href="../reference/hf_classify_df.html">hf_classify_df()</a></code> function, and
some ideas transfer to other providers and their functions,
e.g. <code>oai_*()</code>.</p>
</blockquote>
</div>
<div class="section level2">
<h2 id="set-up">Set Up<a class="anchor" aria-label="anchor" href="#set-up"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tibble.tidyverse.org/" class="external-link">tibble</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyr.tidyverse.org" class="external-link">tidyr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://jpcompartir.github.io/EndpointR/">EndpointR</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org" class="external-link">ggplot2</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://httr2.r-lib.org" class="external-link">httr2</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org" class="external-link">dplyr</a></span><span class="op">)</span></span></code></pre></div>
<p>TODO: Copied from hugging_face_inference.Rmd, need to re-order and
edit</p>
<p>We’ll need some data, so we’ll grab the same sentences and data frame
from the <a href="articles/hugging_face_inference">introductory
vignette</a> on Hugging Face Inference:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">embedding_sentences</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span></span>
<span>  <span class="st">"Text embedding models compress your rambling prose into compact vectors, much like how British commuters squeeze themselves into tube carriages during rush hour."</span>,</span>
<span>  <span class="st">"Setting up an inference endpoint without proper documentation is akin to attempting to navigate London using a map of Birmingham."</span>,</span>
<span>  <span class="st">"When your embedding model starts hallucinating, it's rather like watching Parliament during Question Time—entertaining but utterly unpredictable."</span>,</span>
<span>  <span class="st">"Optimising your inference endpoint is essential unless you fancy your users growing old whilst waiting for a response, perhaps even ageing enough to collect their pension."</span>,</span>
<span>  <span class="st">"The distance between word embeddings reveals semantic relationships, though sadly not the distance between what your client requested and what they actually wanted."</span>,</span>
<span>  <span class="st">"Creating multilingual embeddings is a bit like attempting to order tea properly across Europe—technically possible but fraught with cultural misunderstandings."</span>,</span>
<span>  <span class="st">"Batch processing through inference endpoints saves computing resources, much like how the British save conversation topics by discussing the weather exclusively."</span>,</span>
<span>  <span class="st">"Token limits on embedding APIs are the digital equivalent of a queue at a British post office—inevitably, you'll reach the front just as they close for lunch."</span>,</span>
<span>  <span class="st">"Fine-tuning embedding models on domain-specific corpora is rather like training a British child to apologise—it requires repetition, patience, and considerable examples."</span>,</span>
<span>  <span class="st">"When your inference endpoint crashes under load, it maintains that quintessentially British trait of breaking down precisely when most inconvenient."</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">embedding_ids</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="fl">10</span></span>
<span></span>
<span><span class="va">embedding_df</span> <span class="op">&lt;-</span></span>
<span>  <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span></span>
<span>    id <span class="op">=</span> <span class="va">embedding_ids</span>,</span>
<span>    sentence <span class="op">=</span> <span class="va">embedding_sentences</span></span>
<span>  <span class="op">)</span></span></code></pre></div>
<blockquote>
<p><strong>WARNING</strong>: To follow along you will need to provide
your own endpoint_url and set your own API key. I am using an encrypted
URL for security purposes. <code>ENDPOINTR_KEY</code> is a
person-specific (i.e. you should not have access to my key) environment
variable which can be used to encrypt any information, and should be
stored securely offline, and not committed to GitHub or other online
services.</p>
</blockquote>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">endpoint_url</span> <span class="op">&lt;-</span> <span class="fu">httr2</span><span class="fu">::</span><span class="fu"><a href="https://httr2.r-lib.org/reference/secrets.html" class="external-link">secret_decrypt</a></span><span class="op">(</span><span class="st">"kcZCsc92Ty7PuAk7_FdCcdOU_dlDpvWdDyfpwCWg-wW80eJxJPdQ68nz4V_0922SzSwM5_dYfpTOqsZ-GodUpLN4PQbwE73wlZkBCWIaIXc15g"</span>, <span class="st">"ENDPOINTR_KEY"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="improving-performance---time">Improving Performance - Time<a class="anchor" aria-label="anchor" href="#improving-performance---time"></a>
</h2>
<p>For the <code>hf_embed_df</code> function, our main options are to
increase the number of requests we send simultaneously, and the number
of texts we send within each request.</p>
<ul>
<li>
<code>concurrent_requests</code> lets EndpointR know how many
requests to send at the same time. This should be a number between 1 and
~20-50 (in extreme cases you may be ok with 100, but most endpoints will
not accept this)</li>
<li>
<code>batch_size</code> lets EndpointR know whether to send requests
with individual texts, or with a number of texts ‘batched up’
together.</li>
</ul>
<div class="section level3">
<h3 id="solution-1-concurrent-requests">Solution 1: Concurrent Requests<a class="anchor" aria-label="anchor" href="#solution-1-concurrent-requests"></a>
</h3>
<p>Hugging Face Inference Endpoints can handle multiple requests
arriving at the same time. The goal is to send just under the maximum
number of requests the endpoint can handle. For example, an endpoint
with a powerful GPU may be able to handle hundreds of documents at a
time, whereas an endpoint with a small CPU will be able to handle only a
handful.</p>
<p>As a guide, start with ~5 concurrent requests, and work up to ~20. If
you start hitting rate limits go back down to ~10 and find the
sweetspot. If the endpoint is handling 20 requests without returning
rate limit errors, you could experiment with &gt; 20 requests.</p>
<blockquote>
<p>**TIP*:: Endpoints can be configured to ‘autoscale’ - meaning they
will provide additional hardware when the number of queued requests is
above the configured threshold for the configured duration of time.</p>
</blockquote>
<p>Here we send 5 concurrent requests - this will iterate through the
data frame 5 rows at a time, and send new requests when responses are
returned, until we run out of data to embed.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/hf_embed_df.html">hf_embed_df</a></span><span class="op">(</span></span>
<span>  df <span class="op">=</span> <span class="va">embedding_df</span>,</span>
<span>  text_var <span class="op">=</span> <span class="va">sentence</span>,</span>
<span>  endpoint_url <span class="op">=</span> <span class="va">endpoint_url</span>,</span>
<span>  key_name <span class="op">=</span> <span class="st">"HF_TEST_API_KEY"</span>,</span>
<span>  id_var<span class="op">=</span> <span class="va">id</span>,</span>
<span>  concurrent_requests <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  batch_size <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  progress <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Let’s benchmark performance (see appendix for code) - there is some
overhead associated with generating parallel requests, so we’ll need a
bigger data frame to understand what type of speed up we can get.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">id_1000</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">:</span><span class="fl">1000</span></span>
<span><span class="va">sentences_1000</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="va">embedding_df</span><span class="op">$</span><span class="va">sentence</span>, <span class="fl">100</span><span class="op">)</span></span>
<span><span class="va">embedding_df_1000</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html" class="external-link">tibble</a></span><span class="op">(</span>id <span class="op">=</span> <span class="va">id_1000</span>, sentence <span class="op">=</span> <span class="va">sentences_1000</span><span class="op">)</span></span></code></pre></div>
<p>Recording the results: we can see a ~40% reduction in processing time
when going from 5-&gt; 10 concurrent requests and a ~15% reduction when
going from 10 -&gt; 20 concurrent requests.</p>
<table class="table">
<thead><tr class="header">
<th align="right">concurrent_requests</th>
<th align="right">processing_time_secs</th>
<th align="left">success</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right">5</td>
<td align="right">19.8</td>
<td align="left">TRUE</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">11.9</td>
<td align="left">TRUE</td>
</tr>
<tr class="odd">
<td align="right">20</td>
<td align="right">10.2</td>
<td align="left">TRUE</td>
</tr>
</tbody>
</table>
<p>*Exact times will fluctuate, so take these as approximates.</p>
</div>
<div class="section level3">
<h3 id="solution-2-batching-requests">Solution 2: Batching Requests<a class="anchor" aria-label="anchor" href="#solution-2-batching-requests"></a>
</h3>
<p>Another method for reducing processing time is to send more data
within each request. This will mean we can send fewer requests overall,
and reduce time spent sending information over the network. Sending
multiple rows of data within each request creates a batch request.</p>
<p>If we have 1,000 rows of data, <code>batch_size = 10</code> will
result in 100 requests being sent, instead of the 1,000 with
<code>batch_size = 1</code>.</p>
<blockquote>
<p><strong>TIP</strong>: experiment with batch sizes to find the
sweetspot - usually starting around 8-16, and capping out at ~64. You’ll
know when you’ve gone too high because you’ll start seeing the retry
bar, and/or your responses will contain errors.</p>
</blockquote>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="../reference/hf_embed_df.html">hf_embed_df</a></span><span class="op">(</span></span>
<span>  df <span class="op">=</span> <span class="va">embedding_df_1000</span>,</span>
<span>  text_var <span class="op">=</span> <span class="va">sentence</span>,</span>
<span>  endpoint_url <span class="op">=</span> <span class="va">endpoint_url</span>,</span>
<span>  key_name <span class="op">=</span> <span class="st">"HF_TEST_API_KEY"</span>,</span>
<span>  id_var<span class="op">=</span> <span class="va">id</span>,</span>
<span>  concurrent_requests <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  batch_size <span class="op">=</span> <span class="fl">20</span>,</span>
<span>  progress <span class="op">=</span> <span class="cn">TRUE</span></span>
<span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="solution-3-combining-concurrency-and-batching">Solution 3: Combining Concurrency and Batching<a class="anchor" aria-label="anchor" href="#solution-3-combining-concurrency-and-batching"></a>
</h3>
<p>For maximum speed up, we can also send batches of multiple concurrent
requests. If our endpoint is able to handle them, 10 concurrent requests
of <code>batch_size = 10</code> will be faster than 10 concurrent
requests of <code>batch_size = 5</code>.</p>
</div>
</div>
<div class="section level2">
<h2 id="benchmarking-solutions">Benchmarking Solutions<a class="anchor" aria-label="anchor" href="#benchmarking-solutions"></a>
</h2>
<p>In a separate session and using a dataset which is not available in
the package, we explored the relationship between batch size, concurrent
requests, and throughput ; where throughput is the number of rows
processed per second. We looked at combinations of:</p>
<ul>
<li><strong>batch_size = c(1, 4, 8, 16, 32)</strong></li>
<li><strong>concurrent_requests = c(1, 5, 10, 15, 20)</strong></li>
</ul>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">batch_concurrent_benchmark</span>, package <span class="op">=</span> <span class="st">"EndpointR"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html" class="external-link">kable</a></span><span class="op">(</span><span class="va">batch_concurrent_benchmark</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate_all.html" class="external-link">mutate_if</a></span><span class="op">(</span><span class="va">is.numeric</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">.x</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<table class="table">
<colgroup>
<col width="12%">
<col width="22%">
<col width="13%">
<col width="14%">
<col width="8%">
<col width="16%">
<col width="12%">
</colgroup>
<thead><tr class="header">
<th align="right">batch_size</th>
<th align="right">concurrent_requests</th>
<th align="right">chunk_index</th>
<th align="right">elapsed_time</th>
<th align="left">success</th>
<th align="right">rows_processed</th>
<th align="right">throughput</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">921.77</td>
<td align="left">TRUE</td>
<td align="right">1995</td>
<td align="right">2.16</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">5</td>
<td align="right">3</td>
<td align="right">112.84</td>
<td align="left">TRUE</td>
<td align="right">1996</td>
<td align="right">17.69</td>
</tr>
<tr class="odd">
<td align="right">1</td>
<td align="right">10</td>
<td align="right">4</td>
<td align="right">54.37</td>
<td align="left">TRUE</td>
<td align="right">1998</td>
<td align="right">36.75</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">20</td>
<td align="right">5</td>
<td align="right">26.38</td>
<td align="left">TRUE</td>
<td align="right">1999</td>
<td align="right">75.77</td>
</tr>
<tr class="odd">
<td align="right">4</td>
<td align="right">1</td>
<td align="right">6</td>
<td align="right">200.85</td>
<td align="left">TRUE</td>
<td align="right">1996</td>
<td align="right">9.94</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">5</td>
<td align="right">7</td>
<td align="right">35.10</td>
<td align="left">TRUE</td>
<td align="right">1997</td>
<td align="right">56.90</td>
</tr>
<tr class="odd">
<td align="right">4</td>
<td align="right">10</td>
<td align="right">8</td>
<td align="right">25.28</td>
<td align="left">TRUE</td>
<td align="right">2000</td>
<td align="right">79.12</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">20</td>
<td align="right">9</td>
<td align="right">14.11</td>
<td align="left">TRUE</td>
<td align="right">1999</td>
<td align="right">141.62</td>
</tr>
<tr class="odd">
<td align="right">8</td>
<td align="right">1</td>
<td align="right">10</td>
<td align="right">102.14</td>
<td align="left">TRUE</td>
<td align="right">1996</td>
<td align="right">19.54</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="right">5</td>
<td align="right">11</td>
<td align="right">20.71</td>
<td align="left">TRUE</td>
<td align="right">1998</td>
<td align="right">96.48</td>
</tr>
<tr class="odd">
<td align="right">8</td>
<td align="right">10</td>
<td align="right">12</td>
<td align="right">13.23</td>
<td align="left">TRUE</td>
<td align="right">1995</td>
<td align="right">150.82</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="right">20</td>
<td align="right">13</td>
<td align="right">10.20</td>
<td align="left">TRUE</td>
<td align="right">1998</td>
<td align="right">195.85</td>
</tr>
<tr class="odd">
<td align="right">16</td>
<td align="right">1</td>
<td align="right">14</td>
<td align="right">75.39</td>
<td align="left">TRUE</td>
<td align="right">1995</td>
<td align="right">26.46</td>
</tr>
<tr class="even">
<td align="right">16</td>
<td align="right">5</td>
<td align="right">15</td>
<td align="right">20.16</td>
<td align="left">TRUE</td>
<td align="right">1999</td>
<td align="right">99.14</td>
</tr>
<tr class="odd">
<td align="right">16</td>
<td align="right">10</td>
<td align="right">16</td>
<td align="right">12.86</td>
<td align="left">TRUE</td>
<td align="right">1999</td>
<td align="right">155.40</td>
</tr>
<tr class="even">
<td align="right">16</td>
<td align="right">20</td>
<td align="right">17</td>
<td align="right">14.35</td>
<td align="left">TRUE</td>
<td align="right">1998</td>
<td align="right">139.23</td>
</tr>
<tr class="odd">
<td align="right">32</td>
<td align="right">1</td>
<td align="right">18</td>
<td align="right">64.83</td>
<td align="left">TRUE</td>
<td align="right">2000</td>
<td align="right">30.85</td>
</tr>
<tr class="even">
<td align="right">32</td>
<td align="right">5</td>
<td align="right">19</td>
<td align="right">15.87</td>
<td align="left">TRUE</td>
<td align="right">2000</td>
<td align="right">126.04</td>
</tr>
<tr class="odd">
<td align="right">32</td>
<td align="right">10</td>
<td align="right">20</td>
<td align="right">12.59</td>
<td align="left">TRUE</td>
<td align="right">2000</td>
<td align="right">158.84</td>
</tr>
<tr class="even">
<td align="right">32</td>
<td align="right">20</td>
<td align="right">1</td>
<td align="right">10.23</td>
<td align="left">TRUE</td>
<td align="right">1998</td>
<td align="right">195.39</td>
</tr>
</tbody>
</table>
<p>To embed
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mo>≈</mo><annotation encoding="application/x-tex">\approx</annotation></semantics></math>
2,000 documents sending them 1 text and 1 request at a time, we get a
throughput of
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mo>≈</mo><annotation encoding="application/x-tex">\approx</annotation></semantics></math>
2.16 texts per second, and it takes over 15 minutes! At the other end,
20 concurrent requests of batch size 8, and 20 concurrent requests of
batch size 32 have a throughput of $$195, which is close to 200x quicke!
And we get our results back in 10 seconds.</p>
<blockquote>
<p><strong>NOTE</strong>: If we needed to, we could re-run the
benchmarking code multiple times but the general trend is very
clear.</p>
</blockquote>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">batch_concurrent_benchmark</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>batch_size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">factor</a></span><span class="op">(</span><span class="va">batch_size</span><span class="op">)</span>, concurrent_requests<span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">factor</a></span><span class="op">(</span><span class="va">concurrent_requests</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x<span class="op">=</span> <span class="va">batch_size</span>, y <span class="op">=</span> <span class="va">throughput</span>, group <span class="op">=</span> <span class="va">concurrent_requests</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html" class="external-link">geom_point</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>colour <span class="op">=</span> <span class="va">concurrent_requests</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html" class="external-link">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>colour <span class="op">=</span> <span class="va">concurrent_requests</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>y <span class="op">=</span> <span class="st">"Throughput"</span>, x <span class="op">=</span> <span class="st">"Batch Size"</span>, title <span class="op">=</span> <span class="st">"Increasing `batch_size` and `concurrent_requests` increases throughput"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_viridis.html" class="external-link">scale_colour_viridis_d</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html" class="external-link">theme_minimal</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html" class="external-link">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"bottom"</span><span class="op">)</span> </span></code></pre></div>
<p><img src="improving_performance_files/figure-html/unnamed-chunk-6-1.png" class="r-plt" width="700"></p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">batch_concurrent_benchmark</span> <span class="op">|&gt;</span> </span>
<span>    <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>batch_size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">factor</a></span><span class="op">(</span><span class="va">batch_size</span><span class="op">)</span>, </span>
<span>           concurrent_requests <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html" class="external-link">factor</a></span><span class="op">(</span><span class="va">concurrent_requests</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span>  </span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html" class="external-link">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">batch_size</span>, y <span class="op">=</span> <span class="va">concurrent_requests</span>, fill <span class="op">=</span> <span class="va">throughput</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_tile.html" class="external-link">geom_tile</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_text.html" class="external-link">geom_text</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html" class="external-link">aes</a></span><span class="op">(</span>label <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">throughput</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span>, colour <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_viridis.html" class="external-link">scale_fill_viridis_c</a></span><span class="op">(</span>name <span class="op">=</span> <span class="st">"Throughput"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html" class="external-link">theme_minimal</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html" class="external-link">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Batch Size"</span>, y <span class="op">=</span> <span class="st">"Concurrent Requests"</span>,</span>
<span>         title <span class="op">=</span> <span class="st">"Throughput by Batch Size and Concurrent Requests"</span><span class="op">)</span> <span class="op">+</span></span>
<span>    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html" class="external-link">theme</a></span><span class="op">(</span>legend.position <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span></span></code></pre></div>
<p><img src="improving_performance_files/figure-html/unnamed-chunk-7-1.png" class="r-plt" width="700"></p>
<p>Which parameter is more important for speed,
<code>batch_size =</code> or <code>concurrent_requests =</code>? By eye
it looks like concurrent_requests has the bigger effect, but it’s clear
that both parameters have a positive effect, and within the boundaries
of our parameters, there is an approximately linear relationship between
them and throughput.</p>
<p>Putting together a quick linear model confirms that everything else
equal, increasing <code>concurrent_requests</code> increases throughput
more than <code>batch_size</code></p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html" class="external-link">lm</a></span><span class="op">(</span><span class="va">throughput</span> <span class="op">~</span> <span class="va">batch_size</span> <span class="op">+</span> <span class="va">concurrent_requests</span>, data <span class="op">=</span> <span class="va">batch_concurrent_benchmark</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">broom</span><span class="fu">::</span><span class="fu"><a href="https://generics.r-lib.org/reference/tidy.html" class="external-link">tidy</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span> <span class="op">|&gt;</span>  </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/across.html" class="external-link">across</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">estimate</span>, <span class="va">std.error</span>, <span class="va">statistic</span><span class="op">)</span>, <span class="op">~</span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">.x</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 3 × 5</span></span></span>
<span><span class="co">#&gt;   term                estimate std.error statistic   p.value</span></span>
<span><span class="co">#&gt;   <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>                  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>     <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>     <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>     <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">1</span> (Intercept)             3.34     15.5       0.22 0.832    </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">2</span> batch_size              2.4       0.71      3.37 0.003<span style="text-decoration: underline;">66</span>  </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">3</span> concurrent_requests     6.45      1.12      5.77 0.000<span style="text-decoration: underline;">022</span>4</span></span></code></pre></div>
<blockquote>
<p><strong>QUESTION</strong>: What might happen if we keep increasing
<code>batch_size</code> and <code>concurrent_requests</code>? Will the
relationship hold or not?</p>
</blockquote>
</div>
<div class="section level2">
<h2 id="understanding-the-memory-problem">Understanding the Memory Problem<a class="anchor" aria-label="anchor" href="#understanding-the-memory-problem"></a>
</h2>
<p>TODO:</p>
<div class="section level3">
<h3 id="appendix---embeddings">Appendix - Embeddings<a class="anchor" aria-label="anchor" href="#appendix---embeddings"></a>
</h3>
<p>TODO: out of date post-refactoring</p>
<div class="section level4">
<h4 id="benchmarking-concurrent-requests">Benchmarking Concurrent Requests<a class="anchor" aria-label="anchor" href="#benchmarking-concurrent-requests"></a>
</h4>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">run_benchmark</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">num_concurrent</span>, <span class="va">data</span>, <span class="va">endpoint</span>, <span class="va">key</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">start_time</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Sys.time.html" class="external-link">Sys.time</a></span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="va">res_df</span> <span class="op">&lt;-</span> <span class="kw"><a href="https://rdrr.io/r/base/try.html" class="external-link">try</a></span><span class="op">(</span><span class="fu"><a href="../reference/hf_embed_df.html">hf_embed_df</a></span><span class="op">(</span></span>
<span>                  df <span class="op">=</span> <span class="va">data</span>,</span>
<span>                  text_var <span class="op">=</span> <span class="va">sentence</span>, </span>
<span>                  id_var<span class="op">=</span> <span class="va">id</span>,         </span>
<span>                  endpoint_url <span class="op">=</span> <span class="va">endpoint</span>,</span>
<span>                  key_name <span class="op">=</span> <span class="va">key</span>,</span>
<span>                  include_errors <span class="op">=</span> <span class="cn">FALSE</span>, </span>
<span>                  concurrent_requests <span class="op">=</span> <span class="va">num_concurrent</span>,</span>
<span>                  progress <span class="op">=</span> <span class="cn">FALSE</span> </span>
<span>                <span class="op">)</span>, silent <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> </span>
<span>  <span class="va">processing_time</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Sys.time.html" class="external-link">Sys.time</a></span><span class="op">(</span><span class="op">)</span> <span class="op">-</span> <span class="va">start_time</span></span>
<span>  <span class="va">success</span> <span class="op">&lt;-</span> <span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/class.html" class="external-link">inherits</a></span><span class="op">(</span><span class="va">res_df</span>, <span class="st">"try-error"</span><span class="op">)</span> <span class="op">&amp;&amp;</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">res_df</span><span class="op">)</span> <span class="op">==</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span></span>
<span>    concurrent_requests <span class="op">=</span> <span class="va">num_concurrent</span>,</span>
<span>    processing_time_secs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="va">processing_time</span>, units <span class="op">=</span> <span class="st">"secs"</span><span class="op">)</span>,</span>
<span>    success <span class="op">=</span> <span class="va">success</span></span>
<span>  <span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span></span>
<span><span class="va">num_requests_vec</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">10</span>, <span class="fl">20</span><span class="op">)</span></span>
<span><span class="va">results_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="va">num_requests_vec</span>, <span class="kw">function</span><span class="op">(</span><span class="va">n</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="fu">run_benchmark</span><span class="op">(</span></span>
<span>    num_concurrent <span class="op">=</span> <span class="va">n</span>,</span>
<span>    data <span class="op">=</span> <span class="va">embedding_df_1000</span>,</span>
<span>    endpoint <span class="op">=</span> <span class="va">endpoint_url</span>,</span>
<span>    key <span class="op">=</span> <span class="st">"HF_TEST_API_KEY"</span> </span>
<span>  <span class="op">)</span></span>
<span><span class="op">}</span><span class="op">)</span></span>
<span></span>
<span><span class="op">(</span><span class="va">summary_df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/do.call.html" class="external-link">do.call</a></span><span class="op">(</span><span class="va">rbind</span>, <span class="va">results_list</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="benchmarking-batch-and-concurrent-requests">Benchmarking Batch and Concurrent Requests<a class="anchor" aria-label="anchor" href="#benchmarking-batch-and-concurrent-requests"></a>
</h4>
<p>You won’t be able to re-run this exactly as-is, as the data frame is
not provided with the package. You could bring your own data if you
wanted to do this.</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">trust</span> <span class="op">&lt;-</span> <span class="fu">readr</span><span class="fu">::</span><span class="fu"><a href="https://readr.tidyverse.org/reference/read_delim.html" class="external-link">read_csv</a></span><span class="op">(</span><span class="st">"~/data/trust/trust_slice_spam_classification.csv"</span><span class="op">)</span> <span class="op">|&gt;</span> </span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html" class="external-link">select</a></span><span class="op">(</span><span class="va">text</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>id <span class="op">=</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/row_number.html" class="external-link">row_number</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html" class="external-link">filter</a></span><span class="op">(</span><span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html" class="external-link">is.na</a></span><span class="op">(</span><span class="va">text</span><span class="op">)</span>, <span class="va">text</span> <span class="op">!=</span> <span class="st">""</span><span class="op">)</span> <span class="co"># stop NAs and empty vals crashing anything</span></span>
<span></span>
<span><span class="va">chunk_size</span> <span class="op">&lt;-</span> <span class="fl">2000</span></span>
<span><span class="va">total_chunks</span> <span class="op">&lt;-</span> <span class="fl">20</span></span>
<span></span>
<span><span class="co"># this chunking logic is actually rubbish.</span></span>
<span><span class="va">trust_chunks</span> <span class="op">&lt;-</span> <span class="va">trust</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>chunk_id <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">ceiling</a></span><span class="op">(</span><span class="va">id</span> <span class="op">/</span> <span class="va">chunk_size</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/group_split.html" class="external-link">group_split</a></span><span class="op">(</span><span class="va">chunk_id</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">total_chunks</span><span class="op">)</span></span>
<span></span>
<span><span class="va">benchmark_params</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tidyr.tidyverse.org/reference/expand.html" class="external-link">crossing</a></span><span class="op">(</span></span>
<span>  batch_size <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">4</span>, <span class="fl">8</span>, <span class="fl">16</span>, <span class="fl">32</span><span class="op">)</span>,</span>
<span>  concurrent_requests <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">5</span>, <span class="fl">10</span>, <span class="fl">20</span><span class="op">)</span></span>
<span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>chunk_index <span class="op">=</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/row_number.html" class="external-link">row_number</a></span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/Arithmetic.html" class="external-link">%%</a></span> <span class="va">total_chunks</span> <span class="op">+</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="va">benchmark_results</span> <span class="op">&lt;-</span> <span class="va">benchmark_params</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html" class="external-link">mutate</a></span><span class="op">(</span>result <span class="op">=</span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/pmap.html" class="external-link">pmap</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="va">batch_size</span>, <span class="va">concurrent_requests</span>, <span class="va">chunk_index</span><span class="op">)</span>, <span class="kw">function</span><span class="op">(</span><span class="va">bs</span>, <span class="va">cr</span>, <span class="va">ci</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">current_chunk</span> <span class="op">&lt;-</span> <span class="va">trust_chunks</span><span class="op">[[</span><span class="va">ci</span><span class="op">]</span><span class="op">]</span></span>
<span></span>
<span>    <span class="va">start_time</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Sys.time.html" class="external-link">Sys.time</a></span><span class="op">(</span><span class="op">)</span></span>
<span></span>
<span>    <span class="va">res</span> <span class="op">&lt;-</span> <span class="kw"><a href="https://rdrr.io/r/base/try.html" class="external-link">try</a></span><span class="op">(</span><span class="fu"><a href="../reference/hf_embed_df.html">hf_embed_df</a></span><span class="op">(</span></span>
<span>      df <span class="op">=</span> <span class="va">current_chunk</span>,</span>
<span>      text_var <span class="op">=</span> <span class="va">text</span>,</span>
<span>      id_var <span class="op">=</span> <span class="va">id</span>,</span>
<span>      endpoint_url <span class="op">=</span> <span class="va">endpoint_url</span>,</span>
<span>      key_name <span class="op">=</span> <span class="st">"HF_TEST_API_KEY"</span>,</span>
<span>      batch_size <span class="op">=</span> <span class="va">bs</span>,</span>
<span>      concurrent_requests <span class="op">=</span> <span class="va">cr</span>,</span>
<span>      progress <span class="op">=</span> <span class="cn">TRUE</span></span>
<span>    <span class="op">)</span>, silent <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span>    <span class="va">elapsed_time</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html" class="external-link">as.numeric</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Sys.time.html" class="external-link">Sys.time</a></span><span class="op">(</span><span class="op">)</span> <span class="op">-</span> <span class="va">start_time</span>, units <span class="op">=</span> <span class="st">"secs"</span><span class="op">)</span></span>
<span>    <span class="va">success</span> <span class="op">&lt;-</span> <span class="op">!</span><span class="fu"><a href="https://rdrr.io/r/base/class.html" class="external-link">inherits</a></span><span class="op">(</span><span class="va">res</span>, <span class="st">"try-error"</span><span class="op">)</span></span>
<span>    <span class="va">rows_processed</span> <span class="op">&lt;-</span> <span class="kw">if</span><span class="op">(</span><span class="va">success</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html" class="external-link">nrow</a></span><span class="op">(</span><span class="va">current_chunk</span><span class="op">)</span> <span class="kw">else</span> <span class="fl">0</span></span>
<span></span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span>
<span>      elapsed_time <span class="op">=</span> <span class="va">elapsed_time</span>,</span>
<span>      success <span class="op">=</span> <span class="va">success</span>,</span>
<span>      rows_processed <span class="op">=</span> <span class="va">rows_processed</span>,</span>
<span>      throughput <span class="op">=</span> <span class="kw">if</span><span class="op">(</span><span class="va">success</span><span class="op">)</span> <span class="va">rows_processed</span> <span class="op">/</span> <span class="va">elapsed_time</span> <span class="kw">else</span> <span class="fl">0</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">}</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu">nest_wider</span><span class="op">(</span><span class="va">result</span><span class="op">)</span></span></code></pre></div>
</div>
</div>
<div class="section level3">
<h3 id="appendix---classification">Appendix - Classification<a class="anchor" aria-label="anchor" href="#appendix---classification"></a>
</h3>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by <a href="https://github.com/jpcompartir" class="external-link">Jack Penzer</a>.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
